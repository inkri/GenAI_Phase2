{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177579f3-b91e-41f0-9d5e-d7e846eeab22",
   "metadata": {},
   "source": [
    "# OpenAI Swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8cd60c-3d53-4b83-86ba-a02fd5c9372d",
   "metadata": {},
   "source": [
    "## Use case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d09b53b-feca-4615-b113-cea641f8c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from duckduckgo_search import DDGS\n",
    "from swarm import Swarm, Agent\n",
    "from datetime import datetime\n",
    "\n",
    "clientOI = AzureOpenAI(\n",
    "    api_key=\"abc\",  \n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    azure_endpoint = \"https://ai-proxy.lab.samy.com\"\n",
    "    )\n",
    "\n",
    "# Initialize Swarm client\n",
    "client = Swarm(client=clientOI)\n",
    "current_date = datetime.now().strftime(\"%Y-%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db0f2eb-9b43-47f9-822e-ff159d8e97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Internet Search Tool\n",
    "\n",
    "def get_news_articles(topic):\n",
    "    print(f\"Running DuckDuckGo news search for {topic}...\")\n",
    "    \n",
    "    # DuckDuckGo search\n",
    "    ddg_api = DDGS()\n",
    "    results = ddg_api.text(f\"{topic} {current_date}\", max_results=5)\n",
    "    if results:\n",
    "        news_results = \"\\n\\n\".join([f\"Title: {result['title']}\\nURL: {result['href']}\\nDescription: {result['body']}\" for result in results])\n",
    "        return news_results\n",
    "    else:\n",
    "        return f\"Could not find news results for {topic}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83217da6-51f1-4dec-a02d-22484b4525f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create AI Agents\n",
    "\n",
    "# News Agent to fetch news\n",
    "news_agent = Agent(\n",
    "    name=\"News Assistant\",\n",
    "    instructions=\"You provide the latest news articles for a given topic using DuckDuckGo search.\",\n",
    "    functions=[get_news_articles],\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# Editor Agent to edit news\n",
    "editor_agent = Agent(\n",
    "    name=\"Editor Assistant\",\n",
    "    instructions=\"Rewrite and give me as news article ready for publishing. Each News story in separate section.\",\n",
    "    model=\"gpt-4o\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b6f359-047c-4359-9ec0-ed7e52d5b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create workflow\n",
    "\n",
    "def run_news_workflow(topic):\n",
    "    print(\"Running news Agent workflow...\")\n",
    "    \n",
    "    # Step 1: Fetch news\n",
    "    news_response = client.run(\n",
    "        agent=news_agent,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Get me the news about {topic} on {current_date}\"}],\n",
    "    )\n",
    "    \n",
    "    raw_news = news_response.messages[-1][\"content\"]\n",
    "    \n",
    "    # Step 2: Pass news to editor for final review\n",
    "    edited_news_response = client.run(\n",
    "        agent=editor_agent,\n",
    "        messages=[{\"role\": \"user\", \"content\": raw_news }],\n",
    "    )\n",
    "    \n",
    "    return edited_news_response.messages[-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2746ba-2f62-4a51-8e55-6748b1ebfcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running news Agent workflow...\n",
      "Running DuckDuckGo news search for AI...\n",
      "## Donald Trump's Election Victory Poised to Overturn Biden AI Policies\n",
      "\n",
      "In a historic turn of events, Donald Trump has emerged victorious in the 2024 U.S. presidential election. His win sets the stage for a major overhaul of current federal policies on artificial intelligence (AI). As he prepares to take office, all eyes are on the impending changes to the AI regulations implemented during Joe Biden's administration. This development is projected to impact various sectors reliant on AI technologies. [Read more](https://arstechnica.com/ai/2024/11/trump-victory-signals-major-shakeup-for-us-ai-regulations/)\n",
      "\n",
      "## Biden Administration Releases Comprehensive AI National Security Memorandum\n",
      "\n",
      "On October 24, 2024, the Biden administration unveiled a pivotal document detailing strategies for AI within the sphere of national security. This memorandum outlines a timeline and an index of responsibilities intended to fortify the United States' leadership in AI technology. The document is a vital component of the administration's efforts to integrate AI more effectively into national defense strategies. [Read more](https://georgetownsecuritystudiesreview.org/2024/11/04/the-2024-national-security-memorandum-on-ai-a-timeline-and-index-of-responsibilities/)\n",
      "\n",
      "## Meta Authorizes Use of Its AI Models for U.S. Military\n",
      "\n",
      "In a move that marks a significant shift in corporate policy, Meta has announced that its artificial intelligence models are now available for use by U.S. government agencies and military contractors. This decision includes a potential realignment of AI development for defense purposes, stirring discussions about the militarization of commercial technology. [Read more](https://www.nytimes.com/2024/11/04/technology/meta-ai-military.html)\n",
      "\n",
      "## AI's Transformative Potential in Medicine Hindered by Data Access Challenges\n",
      "\n",
      "Artificial intelligence stands on the verge of transforming the healthcare industry, promising groundbreaking advances. However, a major hurdle persists: the availability and accessibility of essential data. Innovators face significant challenges in obtaining the data needed to propel AI-driven healthcare solutions forward, a factor that may impede progress in this promising field. [Read more](https://www.bloomberg.com/opinion/articles/2024-11-07/ai-can-transform-medicine-if-innovators-gain-needed-data-access)\n",
      "\n",
      "## Biden-Harris Administration Unveils AI National Security Plan\n",
      "\n",
      "The Biden-Harris administration has issued a fact sheet that outlines a coordinated strategy for employing artificial intelligence in strengthening U.S. national security. This strategy focuses on enhancing research capabilities and fostering partnerships. By harnessing AI, the administration aims to create a more robust framework for defense and security, ensuring technological superiority in these critical areas. [Read more](https://www.whitehouse.gov/briefing-room/statements-releases/2024/10/24/fact-sheet-biden-harris-administration-outlines-coordinated-approach-to-harness-power-of-ai-for-u-s-national-security/)\n",
      "\n",
      "These articles collectively underscore AI's shifting role across various domains, from its integration into national defense strategies to its transformational impact on global healthcare systems.\n"
     ]
    }
   ],
   "source": [
    "# Example of running the news workflow for a given topic\n",
    "print(run_news_workflow(\"AI\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb7964-e1e3-4e73-80ae-41c775163e49",
   "metadata": {},
   "source": [
    "## Use case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f75affe8-782d-4a2b-9678-ab03375c7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from duckduckgo_search import DDGS\n",
    "from swarm import Swarm, Agent\n",
    "from datetime import datetime\n",
    "from sentence_transformers import util\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Set up AzureOpenAI client\n",
    "clientOI = AzureOpenAI(\n",
    "    api_key=\"abc\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    azure_endpoint=\"https://ai-proxy.lab.samy.com\"\n",
    ")\n",
    "\n",
    "# Initialize Swarm client\n",
    "client = Swarm(client=clientOI)\n",
    "current_date = datetime.now().strftime(\"%Y-%m\")\n",
    "\n",
    "# Load the mpnet model from sentence-transformers\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573f2822-6df1-412d-b1a1-a96b5bf8b0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2addda68f24f48be619b0c566dccc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Abhishek_Jaiswal\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a76a520f8ad406aa0d0f59c0a837417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a7cd0dcf9c4852a70952a4de8d32d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f5a5596aaa4f9796d65bc5d8d6833d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e662c6c052418caf2a7b73d003b46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9788f452096347dfbba582bf0d598a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03db36b011f8408cb8f9d294d6a19ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a536b3cc2b2847eebb0264c3148d97af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17dd0e0fbf6463c937f611b1960b873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077e14264fa146a7aa8dfb18f05a0ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faedef0f99e940489076599d4227cee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine learning is a subset of artificial int...</td>\n",
       "      <td>AI</td>\n",
       "      <td>[-0.02844554, -0.0067215366, -0.07253845, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python is commonly used for data science and m...</td>\n",
       "      <td>Python</td>\n",
       "      <td>[0.012467294, 0.02821976, -0.035361845, -0.021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deep learning algorithms require large amounts...</td>\n",
       "      <td>AI</td>\n",
       "      <td>[-0.029015891, 0.122301586, -0.030206438, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers are state-of-the-art models for N...</td>\n",
       "      <td>NLP</td>\n",
       "      <td>[0.06630315, 0.05206603, -0.023457907, 0.02128...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   topic  \\\n",
       "0  Machine learning is a subset of artificial int...      AI   \n",
       "1  Python is commonly used for data science and m...  Python   \n",
       "2  Deep learning algorithms require large amounts...      AI   \n",
       "3  Transformers are state-of-the-art models for N...     NLP   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.02844554, -0.0067215366, -0.07253845, -0.0...  \n",
       "1  [0.012467294, 0.02821976, -0.035361845, -0.021...  \n",
       "2  [-0.029015891, 0.122301586, -0.030206438, 0.03...  \n",
       "3  [0.06630315, 0.05206603, -0.023457907, 0.02128...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample RAG DataFrame\n",
    "def create_rag_dataframe():\n",
    "    data = {\n",
    "        \"text\": [\n",
    "            \"Machine learning is a subset of artificial intelligence.\",\n",
    "            \"Python is commonly used for data science and machine learning.\",\n",
    "            \"Deep learning algorithms require large amounts of data.\",\n",
    "            \"Transformers are state-of-the-art models for NLP tasks.\"\n",
    "        ],\n",
    "        \"topic\": [\"AI\", \"Python\", \"AI\", \"NLP\"]\n",
    "    }\n",
    "    \n",
    "    # Generate mpnet embeddings for each text entry\n",
    "    data['embedding'] = [model.encode(text) for text in data['text']]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Create the RAG DataFrame\n",
    "rag_df = create_rag_dataframe()\n",
    "rag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1391b925-6e4c-4ccc-ad70-1caf7fe4c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Internet Search Tool\n",
    "def get_news_articles(topic):\n",
    "    print(f\"Running DuckDuckGo news search for {topic}...\")\n",
    "    ddg_api = DDGS()\n",
    "    results = ddg_api.text(f\"{topic} {current_date}\", max_results=5)\n",
    "    if results:\n",
    "        news_results = \"\\n\\n\".join(\n",
    "            [f\"Title: {result['title']}\\nURL: {result['href']}\\nDescription: {result['body']}\" for result in results]\n",
    "        )\n",
    "        return news_results\n",
    "    else:\n",
    "        return f\"Could not find news results for {topic}.\"\n",
    "\n",
    "# RAG Retrieval Function\n",
    "def retrieve_rag_answer(topic):\n",
    "    # Generate the mpnet embedding for the input topic\n",
    "    topic_embedding = model.encode(topic)\n",
    "\n",
    "    # Compute cosine similarity between topic_embedding and each embedding in rag_df\n",
    "    rag_df['similarity'] = rag_df['embedding'].apply(lambda x: util.cos_sim(x, topic_embedding).item())\n",
    "\n",
    "    # Retrieve the most similar row\n",
    "    relevant_row = rag_df.loc[rag_df['similarity'].idxmax()]\n",
    "\n",
    "    # Return the text if similarity is above a threshold, otherwise return a default response\n",
    "    return relevant_row['text'] if relevant_row['similarity'] > 0.5 else \"No relevant information found.\"\n",
    "\n",
    "\n",
    "# 2. Create AI Agents\n",
    "# Greeting Agent\n",
    "greeting_agent = Agent(\n",
    "    name=\"Greeting Agent\",\n",
    "    instructions=\"Respond with a friendly greeting.\",\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# Irrelevant Agent\n",
    "irrelevant_agent = Agent(\n",
    "    name=\"Irrelevant Agent\",\n",
    "    instructions=\"Handle irrelevant queries by politely asking the user to rephrase.\",\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# News Agent for online search\n",
    "news_agent = Agent(\n",
    "    name=\"News Agent\",\n",
    "    instructions=\"Provide the latest news articles for a given topic using DuckDuckGo search.\",\n",
    "    functions=[get_news_articles],\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# RAG Agent\n",
    "rag_agent = Agent(\n",
    "    name=\"RAG Agent\",\n",
    "    instructions=\"Retrieve answers from a knowledge base for queries on specific topics.\",\n",
    "    functions=[retrieve_rag_answer],\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# 3. Define bot workflow\n",
    "def conversation_bot(user_input):\n",
    "    if any(greet in user_input.lower() for greet in [\"hello\", \"hi\", \"hey\"]):\n",
    "        response = client.run(agent=greeting_agent, messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "        return response.messages[-1][\"content\"]\n",
    "\n",
    "    elif \"news\" in user_input.lower():\n",
    "        topic = user_input.split(\"about\")[-1].strip()\n",
    "        response = client.run(agent=news_agent, messages=[{\"role\": \"user\", \"content\": f\"Get news on {topic}\"}])\n",
    "        return response.messages[-1][\"content\"]\n",
    "    \n",
    "    elif any(topic in user_input.lower() for topic in rag_df['topic'].unique()):\n",
    "        topic = [topic for topic in rag_df['topic'].unique() if topic in user_input.lower()][0]\n",
    "        response = client.run(agent=rag_agent, messages=[{\"role\": \"user\", \"content\": f\"Retrieve info on {topic}\"}])\n",
    "        return response.messages[-1][\"content\"]\n",
    "    \n",
    "    else:\n",
    "        response = client.run(agent=irrelevant_agent, messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "        return response.messages[-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37905960-2500-4de6-ae56-bd9825d18619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "print(conversation_bot(\"Hello!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46f439c-de7a-4675-8187-7280d78f329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DuckDuckGo news search for AI...\n",
      "Here are the latest news articles on AI:\n",
      "\n",
      "1. **Trump plans to dismantle Biden AI safeguards after victory**  \n",
      "   Early Wednesday morning, Donald Trump became the presumptive winner of the 2024 US presidential election, setting the stage for dramatic changes to federal AI policy when he takes office.  \n",
      "   [Read more here](https://arstechnica.com/ai/2024/11/trump-victory-signals-major-shakeup-for-us-ai-regulations/)\n",
      "\n",
      "2. **The 2024 National Security Memorandum on AI: A Timeline and Index of Responsibilities**  \n",
      "   On October 24, 2024, the Biden administration published a memorandum focused on advancing the United States' leadership in AI, harnessing AI for national security, and fostering safety and trustworthiness.  \n",
      "   [Read more here](https://georgetownsecuritystudiesreview.org/2024/11/04/the-2024-national-security-memorandum-on-ai-a-timeline-and-index-of-responsibilities/)\n",
      "\n",
      "3. **Fact Sheet: Key AI Accomplishments in the Year Since the Biden Administration’s Landmark Executive Order**  \n",
      "   The administration has engaged foreign leaders to strengthen international rules for AI, demonstrated at the UK AI Safety Summit and the AI Seoul Summit in 2024.  \n",
      "   [Read more here](https://www.whitehouse.gov/briefing-room/statements-releases/2024/10/30/fact-sheet-key-ai-accomplishments-in-the-year-since-the-biden-harris-administrations-landmark-executive-order/)\n",
      "\n",
      "4. **The state of AI in early 2024: Gen AI adoption spikes and starts to generate value**  \n",
      "   This report provides insights into the increased adoption of generative AI and its impact across various markets.  \n",
      "   [Read more here (PDF)](https://www.mckinsey.com/~/media/mckinsey/business+functions/quantumblack/our+insights/the+state+of+ai/2024/the-state-of-ai-in-early-2024-final.pdf)\n",
      "\n",
      "5. **Meta Permits Its A.I. Models to Be Used for U.S. Military Purposes**  \n",
      "   Meta has announced that it will allow U.S. government agencies and contractors to use its AI models for military purposes, marking a policy shift.  \n",
      "   [Read more here](https://www.nytimes.com/2024/11/04/technology/meta-ai-military.html)\n"
     ]
    }
   ],
   "source": [
    "print(conversation_bot(\"Get me news about AI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3469b06-4a8a-4eec-bfca-b2a50d376c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a versatile, high-level programming language known for its readability and simplicity. Created by Guido van Rossum and first released in 1991, Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Its clear syntax allows developers to express concepts in fewer lines of code compared to other languages, making it a great choice for both beginners and experienced programmers.\n",
      "\n",
      "One of Python's key strengths is its extensive standard library and a vibrant ecosystem of third-party packages, which extend its capabilities in areas such as web development, data analysis, artificial intelligence, scientific computing, and more. The Python Package Index (PyPI) hosts thousands of modules that can be easily installed to enhance functionality.\n",
      "\n",
      "Python is known for its large and active community, providing plenty of resources, tutorials, and forums for support. This popularity has led to its use in a wide range of applications, from simple scripts to complex enterprise solutions.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_bot(\"Tell me something about Python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d122d3f-9be3-405b-88f9-1909a6081f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I can't provide real-time weather updates. You might want to check a weather app or website for the latest information.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_bot(\"What is the weather today?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf585100-c3be-4200-a106-b82de66419b6",
   "metadata": {},
   "source": [
    "# Use case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8258313c-ab76-4f17-aa2f-5889d8929a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running compliance workflow...\n",
      "Analyzing regulation impact for: New financial reporting requirements for Q4 2024\n",
      "Suggesting amendments for document: Existing contract outlining financial obligations.\n",
      "Suggesting amendments for document: Existing contract outlining financial obligations.\n",
      "Suggesting amendments for document: Existing contract outlining financial obligations.\n",
      "Impact Analysis:\n",
      "The assessment of the new financial reporting requirements for Q4 2024 has identified changes necessary for compliance. If you need further details on the specific documents affected or additional information on how to implement these changes, please let me know!\n",
      "\n",
      "Suggested Amendments:\n",
      "I am currently unable to process the document for compliance suggestions. Could you please provide more specific details or the content of the document you would like amended?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from swarm import Swarm, Agent\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "clientOI = AzureOpenAI(\n",
    "    api_key=\"abc\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    azure_endpoint=\"https://ai-proxy.lab.samy.com\"\n",
    ")\n",
    "\n",
    "# Initialize Swarm client\n",
    "client = Swarm(client=clientOI)\n",
    "current_date = datetime.now().strftime(\"%Y-%m\")\n",
    "\n",
    "# 1. Define Compliance Impact Assessment Agent\n",
    "\n",
    "def assess_regulation_impact(regulation_text):\n",
    "    \"\"\"\n",
    "    Analyzes the impact of a new regulation on existing documents.\n",
    "    \"\"\"\n",
    "    # Placeholder function for analysis\n",
    "    print(f\"Analyzing regulation impact for: {regulation_text}\")\n",
    "    # Simulated output\n",
    "    impact_results = f\"Identified changes required for compliance with regulation: '{regulation_text}'.\"\n",
    "    return impact_results\n",
    "\n",
    "# 2. Define Amendment Suggestion Agent\n",
    "\n",
    "def suggest_amendments(document_text):\n",
    "    \"\"\"\n",
    "    Suggests amendments for the given document text based on compliance requirements.\n",
    "    \"\"\"\n",
    "    # Placeholder function for suggesting amendments\n",
    "    print(f\"Suggesting amendments for document: {document_text}\")\n",
    "    # Simulated output\n",
    "    amendment_suggestions = f\"Suggested amendments for document: '{document_text}'.\"\n",
    "    return amendment_suggestions\n",
    "\n",
    "# 3. Create AI Agents\n",
    "\n",
    "# Agent to assess compliance impact\n",
    "compliance_agent = Agent(\n",
    "    name=\"Compliance Assistant\",\n",
    "    instructions=\"Analyze new regulations and identify required changes in existing documents.\",\n",
    "    functions=[assess_regulation_impact],\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# Agent to suggest amendments\n",
    "amendment_agent = Agent(\n",
    "    name=\"Amendment Assistant\",\n",
    "    instructions=\"Provide suggested amendments for documents based on compliance requirements.\",\n",
    "    functions=[suggest_amendments],\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# 4. Define Workflow\n",
    "\n",
    "def run_compliance_workflow(regulation_text, document_text):\n",
    "    print(\"Running compliance workflow...\")\n",
    "\n",
    "    # Step 1: Assess regulatory impact\n",
    "    compliance_response = client.run(\n",
    "        agent=compliance_agent,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Assess impact of regulation: {regulation_text}\"}],\n",
    "    )\n",
    "\n",
    "    impact_analysis = compliance_response.messages[-1][\"content\"]\n",
    "\n",
    "    # Step 2: Suggest amendments for affected document\n",
    "    amendment_response = client.run(\n",
    "        agent=amendment_agent,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Suggest amendments for document: {document_text}\"}],\n",
    "    )\n",
    "\n",
    "    amendments = amendment_response.messages[-1][\"content\"]\n",
    "\n",
    "    # Combine the results\n",
    "    return f\"Impact Analysis:\\n{impact_analysis}\\n\\nSuggested Amendments:\\n{amendments}\"\n",
    "\n",
    "# Example of running the compliance workflow with a sample regulation and document\n",
    "regulation_text = \"New financial reporting requirements for Q4 2024.\"\n",
    "document_text = \"Existing contract outlining financial obligations.\"\n",
    "\n",
    "print(run_compliance_workflow(regulation_text, document_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625d0b4-f37f-4e82-b62d-dcf61df42103",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem:\n",
    "#Sir needs to assess the impact of regulatory or business changes on existing contracts, identify which documents require amendments, and suggest specific changes. The current process is manual, time-consuming, and lacks clarity.\n",
    "\n",
    "### Solution:\n",
    "#We created a workflow using AI agents:\n",
    "#1. **Compliance Agent**: Analyzes the impact of new regulations on existing documents.\n",
    "#2. **Amendment Agent**: Suggests amendments for the affected documents based on the compliance requirements.\n",
    "#This automated workflow significantly reduces manual effort and provides clear, actionable insights, making compliance management more efficient and streamlined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5e55a-dbd3-41fc-8b64-4de72b3a3f00",
   "metadata": {},
   "source": [
    "# Use case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "decab15b-2b1e-4655-9478-a8ad4f4efd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from datetime import datetime\n",
    "from swarm import Swarm, Agent\n",
    "\n",
    "# Mocking TaskManager class\n",
    "class TaskManager:\n",
    "    def get_tasks(self, persona):\n",
    "        # Simulate fetching tasks based on persona\n",
    "        tasks = {\n",
    "            \"General Counsel\": [\"Review contracts\", \"Attend leadership meeting\", \"Update matter status\"],\n",
    "            \"Legal Ops\": [\"Monitor contract turnaround times\", \"Review legal KPIs\"],\n",
    "            \"Lawyer Manager\": [\"Assign tasks to team\", \"Review case progress\"],\n",
    "            \"Lawyer\": [\"Prepare legal documents\", \"Meet with clients\", \"Submit case reports\"]\n",
    "        }\n",
    "        return tasks.get(persona, [])\n",
    "\n",
    "# Mocking DocumentParser class\n",
    "class DocumentParser:\n",
    "    def extract_dates_and_tasks(self, document_path):\n",
    "        # Simulate extracting dates and tasks from documents\n",
    "        return [\n",
    "            {\"date\": \"2024-11-07\", \"event\": \"Contract Review Deadline\"},\n",
    "            {\"date\": \"2024-11-10\", \"event\": \"Client Meeting\"}\n",
    "        ]\n",
    "\n",
    "# AzureOpenAI client setup\n",
    "clientOI = AzureOpenAI(\n",
    "    api_key=\"abc\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    azure_endpoint=\"https://ai-proxy.lab.samy.com\"\n",
    ")\n",
    "\n",
    "# Initialize Swarm client\n",
    "client = Swarm(client=clientOI)\n",
    "current_date = datetime.now().strftime(\"%Y-%m\")\n",
    "\n",
    "# Initialize TaskManager and DocumentParser\n",
    "task_manager = TaskManager()  # Using the mock TaskManager class\n",
    "document_parser = DocumentParser()  # Using the mock DocumentParser class\n",
    "\n",
    "# 1. Integrate AI to create Persona-specific Dashboards\n",
    "def generate_dashboard(persona):\n",
    "    print(f\"Generating {persona} dashboard...\")\n",
    "\n",
    "    if persona == \"General Counsel\":\n",
    "        dashboard = get_gc_dashboard()\n",
    "    elif persona == \"Legal Ops\":\n",
    "        dashboard = get_legal_ops_dashboard()\n",
    "    elif persona == \"Lawyer Manager\":\n",
    "        dashboard = get_lawyer_manager_dashboard()\n",
    "    elif persona == \"Lawyer\":\n",
    "        dashboard = get_lawyer_dashboard()\n",
    "\n",
    "    return dashboard\n",
    "\n",
    "# Define Dashboard Generation Functions (using LLM to fetch data)\n",
    "def get_gc_dashboard():\n",
    "    # Collect and aggregate data for GC\n",
    "    matter_data = get_matter_data(\"GC\")\n",
    "    budget_data = get_budget_data(\"GC\")\n",
    "    \n",
    "    # LLM for generating a holistic view\n",
    "    dashboard = f\"General Counsel Dashboard: {matter_data}\\nBudget Overview: {budget_data}\"\n",
    "    return dashboard\n",
    "\n",
    "def get_legal_ops_dashboard():\n",
    "    # Collect KPIs and performance data\n",
    "    kpi_data = get_kpi_data(\"Legal Ops\")\n",
    "    return f\"Legal Ops Dashboard: {kpi_data}\"\n",
    "\n",
    "def get_lawyer_manager_dashboard():\n",
    "    # Get matters and team performance\n",
    "    team_matter_data = get_team_matter_data(\"Lawyer Manager\")\n",
    "    return f\"Lawyer Manager Dashboard: {team_matter_data}\"\n",
    "\n",
    "def get_lawyer_dashboard():\n",
    "    # Get individual matters and tasks\n",
    "    personal_matter_data = get_personal_matter_data(\"Lawyer\")\n",
    "    return f\"Lawyer Dashboard: {personal_matter_data}\"\n",
    "\n",
    "# Missing function definitions\n",
    "def get_matter_data(persona):\n",
    "    # Simulate fetching matter data for a specific persona\n",
    "    return f\"Matter Data for {persona}: [Matter 1, Matter 2, Matter 3]\"\n",
    "\n",
    "def get_budget_data(persona):\n",
    "    # Simulate fetching budget data for a specific persona\n",
    "    return f\"Budget Data for {persona}: [Budget 1, Budget 2, Budget 3]\"\n",
    "\n",
    "def get_kpi_data(persona):\n",
    "    # Simulate fetching KPI data for a specific persona\n",
    "    return f\"KPI Data for {persona}: [KPI 1, KPI 2, KPI 3]\"\n",
    "\n",
    "def get_team_matter_data(persona):\n",
    "    # Simulate fetching team matter data for a specific persona\n",
    "    return f\"Team Matter Data for {persona}: [Team Matter 1, Team Matter 2]\"\n",
    "\n",
    "def get_personal_matter_data(persona):\n",
    "    # Simulate fetching personal matter data for a specific persona\n",
    "    return f\"Personal Matter Data for {persona}: [Personal Matter 1, Personal Matter 2]\"\n",
    "\n",
    "# 2. Automated Task Management (sync with task manager)\n",
    "def sync_with_task_manager(persona):\n",
    "    tasks = task_manager.get_tasks(persona)\n",
    "    return tasks\n",
    "\n",
    "# 3. Document Parsing (generate chronology from documents)\n",
    "def generate_chronology_from_documents():\n",
    "    document_data = document_parser.extract_dates_and_tasks(\"matter_documents_path\")\n",
    "    return document_data\n",
    "\n",
    "# 4. Create AI Agents for Persona-Based Workflows\n",
    "dashboard_agent = Agent(\n",
    "    name=\"Dashboard Assistant\",\n",
    "    instructions=\"Provide personalized dashboard data for the assigned persona.\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "# 5. Workflow: Combine all into a unified workflow\n",
    "def run_persona_workflow(persona):\n",
    "    print(\"Running persona-based workflow...\")\n",
    "\n",
    "    # Step 1: Generate Persona Dashboard\n",
    "    dashboard_data = generate_dashboard(persona)\n",
    "    \n",
    "    # Step 2: Sync with Task Manager for updates\n",
    "    task_data = sync_with_task_manager(persona)\n",
    "    \n",
    "    # Step 3: Parse documents for key dates and events\n",
    "    chronology_data = generate_chronology_from_documents()\n",
    "    \n",
    "    # Step 4: Combine all the data for a comprehensive view\n",
    "    full_dashboard = f\"{dashboard_data}\\n{task_data}\\nChronology of Events: {chronology_data}\"\n",
    "    \n",
    "    return full_dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe7848a5-b56c-4176-afad-c1490f2e7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running persona-based workflow...\n",
      "Generating General Counsel dashboard...\n",
      "General Counsel Dashboard: Matter Data for GC: [Matter 1, Matter 2, Matter 3]\n",
      "Budget Overview: Budget Data for GC: [Budget 1, Budget 2, Budget 3]\n",
      "['Review contracts', 'Attend leadership meeting', 'Update matter status']\n",
      "Chronology of Events: [{'date': '2024-11-07', 'event': 'Contract Review Deadline'}, {'date': '2024-11-10', 'event': 'Client Meeting'}]\n"
     ]
    }
   ],
   "source": [
    "# Example usage for the \"General Counsel\" persona\n",
    "print(run_persona_workflow(\"General Counsel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9ac5ddf-9981-4665-bb29-c3981863e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem:\n",
    "#Legal departments often involve multiple personas such as **General Counsel (GC)**, **Legal Operations (Legal Ops)**, **Lawyer Managers**, and **Lawyers**, each requiring personalized access to specific legal data. Gathering and presenting this information manually from various sources is time-consuming and error-prone. These personas need insights into ongoing legal matters, budgets, KPIs, tasks, and document-based events, which are often scattered across different systems.\n",
    "\n",
    "### Solution:\n",
    "#The solution automates the process of generating tailored dashboards for each persona using **AI agents** and task management integration. The core components include:\n",
    "\n",
    "#1. **Persona-based Dashboards**: The code generates dashboards for each persona (e.g., GC, Legal Ops) by aggregating relevant data such as matter details, budgets, and tasks using LLM models.\n",
    "#2. **Task Management**: It integrates with a task management system to fetch real-time tasks for each persona.\n",
    "#3. **Document Parsing**: It uses a **DocumentParser** to extract key dates and milestones from legal documents, creating a chronology for each matter.\n",
    "#4. **AI Agents**: Personalized dashboards are created by running workflows that leverage AI models for data aggregation and timeline generation.\n",
    "\n",
    "#By automating this process, the solution streamlines data access and improves decision-making, providing legal teams with a consolidated view of all necessary information, thus increasing productivity and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a381e3-855e-4feb-91fc-efa2ef601d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f43519f-dce6-4a38-8560-1395070ac320",
   "metadata": {},
   "source": [
    "# Use case 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c91cd-63d2-4d05-a09e-2f7db1917f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from duckduckgo_search import DDGS\n",
    "from swarm import Swarm, Agent\n",
    "from datetime import datetime\n",
    "from sentence_transformers import util\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Set up AzureOpenAI client\n",
    "clientOI = AzureOpenAI(\n",
    "    api_key=\"abc\",\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    azure_endpoint=\"https://ai-proxy.lab.samy.com\"\n",
    ")\n",
    "\n",
    "# Initialize Swarm client\n",
    "client = Swarm(client=clientOI)\n",
    "current_date = datetime.now().strftime(\"%Y-%m\")\n",
    "\n",
    "# Load the mpnet model from sentence-transformers\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Sample RAG DataFrame\n",
    "def create_rag_dataframe():\n",
    "    data = {\n",
    "        \"text\": [\n",
    "            \"Machine learning is a subset of artificial intelligence.\",\n",
    "            \"Python is commonly used for data science and machine learning.\",\n",
    "            \"Deep learning algorithms require large amounts of data.\",\n",
    "            \"Transformers are state-of-the-art models for NLP tasks.\"\n",
    "        ],\n",
    "        \"topic\": [\"AI\", \"Python\", \"AI\", \"NLP\"]\n",
    "    }\n",
    "    \n",
    "    # Generate mpnet embeddings for each text entry\n",
    "    data['embedding'] = [model.encode(text) for text in data['text']]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Create the RAG DataFrame\n",
    "rag_df = create_rag_dataframe()\n",
    "\n",
    "# 1. Internet Search Tool\n",
    "def get_news_articles(topic):\n",
    "    print(f\"Running DuckDuckGo news search for {topic}...\")\n",
    "    ddg_api = DDGS()\n",
    "    results = ddg_api.text(f\"{topic} {current_date}\", max_results=5)\n",
    "    if results:\n",
    "        news_results = \"\\n\\n\".join(\n",
    "            [f\"Title: {result['title']}\\nURL: {result['href']}\\nDescription: {result['body']}\" for result in results]\n",
    "        )\n",
    "        return news_results\n",
    "    else:\n",
    "        return f\"Could not find news results for {topic}.\"\n",
    "\n",
    "# RAG Retrieval Function\n",
    "def retrieve_rag_answer(topic):\n",
    "    topic_embedding = model.encode(topic)\n",
    "    rag_df['similarity'] = rag_df['embedding'].apply(lambda x: util.cos_sim(x, topic_embedding).item())\n",
    "    relevant_row = rag_df.loc[rag_df['similarity'].idxmax()]\n",
    "    return relevant_row['text'] if relevant_row['similarity'] > 0.5 else \"No relevant information found.\"\n",
    "\n",
    "# 2. Create AI Agents\n",
    "greeting_agent = Agent(name=\"Greeting Agent\", instructions=\"Respond with a friendly greeting.\", model=\"gpt-4o\")\n",
    "irrelevant_agent = Agent(name=\"Irrelevant Agent\", instructions=\"Handle irrelevant queries by politely asking the user to rephrase.\", model=\"gpt-4o\")\n",
    "news_agent = Agent(name=\"News Agent\", instructions=\"Provide the latest news articles for a given topic using DuckDuckGo search.\", functions=[get_news_articles], model=\"gpt-4o\")\n",
    "rag_agent = Agent(name=\"RAG Agent\", instructions=\"Retrieve answers from a knowledge base for queries on specific topics.\", functions=[retrieve_rag_answer], model=\"gpt-4o\")\n",
    "\n",
    "# Classification agent for query intent\n",
    "classifier_agent = Agent(\n",
    "    name=\"Classifier Agent\",\n",
    "    instructions=\"Classify the user query into one of the following types: greeting, news, rag, or irrelevant.\",\n",
    "    model=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "# Updated classify_user_query function using the classifier agent\n",
    "def classify_user_query(user_input):\n",
    "    classification_response = client.run(agent=classifier_agent, messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    query_type = classification_response.messages[-1][\"content\"].strip().lower()\n",
    "    return query_type\n",
    "\n",
    "# Updated conversation bot workflow\n",
    "def conversation_bot(user_input):\n",
    "    query_type = classify_user_query(user_input)\n",
    "    \n",
    "    if query_type == \"greeting\":\n",
    "        response = client.run(agent=greeting_agent, messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    \n",
    "    elif query_type == \"news\":\n",
    "        topic = user_input.split(\"about\")[-1].strip()\n",
    "        response = client.run(agent=news_agent, messages=[{\"role\": \"user\", \"content\": f\"Get news on {topic}\"}])\n",
    "    \n",
    "    elif query_type == \"rag\":\n",
    "        topic = [topic for topic in rag_df['topic'].unique() if topic.lower() in user_input.lower()][0]\n",
    "        response = client.run(agent=rag_agent, messages=[{\"role\": \"user\", \"content\": f\"Retrieve info on {topic}\"}])\n",
    "    \n",
    "    else:\n",
    "        response = client.run(agent=irrelevant_agent, messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    \n",
    "    return response.messages[-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd7d8695-e62f-411d-a14f-a1da714a2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DuckDuckGo news search for AI...\n",
      "Here are some of the latest news articles on AI:\n",
      "\n",
      "1. **[The 2024 National Security Memorandum on AI](https://georgetownsecuritystudiesreview.org/2024/11/04/the-2024-national-security-memorandum-on-ai-a-timeline-and-index-of-responsibilities/)**: An article exploring the Biden administration's efforts to advance the United States' leadership in AI while addressing national security and fostering AI safety. \n",
      "\n",
      "2. **[The 5 Biggest Artificial Intelligence Trends For 2024 - Forbes](https://www.forbes.com/sites/bernardmarr/2023/11/01/the-top-5-artificial-intelligence-trends-for-2024/)**: Covers new AI trends for 2024, including quantum advancements and generative AI, influencing human-AI collaborations.\n",
      "\n",
      "3. **[Research: How Gen AI Is Already Impacting the Labor Market](https://hbr.org/2024/11/research-how-gen-ai-is-already-impacting-the-labor-market)**: Analyzes how general AI tools like ChatGPT and image-generating technologies are affecting online gig job markets.\n",
      "\n",
      "4. **[The state of AI in early 2024](https://www.mckinsey.com/~/media/mckinsey/business+functions/quantumblack/our+insights/the+state+of+ai/2024/the-state-of-ai-in-early-2024-final.pdf)**: Report on how generative AI adoption is increasing across various industries and its growing value.\n",
      "\n",
      "5. **[AI Index Report 2024 - Artificial Intelligence Index](https://aiindex.stanford.edu/report/)**: Offers insights into AI developments, noting trends such as the decreasing migration of high-level AI talent from industry to academia.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_bot(\"Get me news about AI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03072fe-ca2c-4650-b253-6e8de0a9d2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

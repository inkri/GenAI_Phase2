{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e569b59-0f31-4046-881a-f4bd917a9008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor Name: Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n",
      "Platform: Windows 10\n",
      "Physical Cores: 4\n",
      "Detailed CPU Info: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz\n"
     ]
    }
   ],
   "source": [
    "#1. Check CPU Info (Cores, Processor, etc.)\n",
    "import os\n",
    "import platform\n",
    "import multiprocessing\n",
    "from cpuinfo import get_cpu_info\n",
    "\n",
    "# CPU info\n",
    "print(\"Processor Name:\", platform.processor())\n",
    "print(\"Platform:\", platform.system(), platform.release())\n",
    "print(\"Physical Cores:\", multiprocessing.cpu_count())\n",
    "print(\"Detailed CPU Info:\", get_cpu_info()['brand_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3020675-0e0a-4698-9dcd-5114c1c034be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM: 15.87 GB\n"
     ]
    }
   ],
   "source": [
    "#2. Check RAM Info\n",
    "import psutil\n",
    "\n",
    "# RAM info\n",
    "ram_bytes = psutil.virtual_memory().total\n",
    "ram_gb = ram_bytes / (1024 ** 3)\n",
    "print(f\"Total RAM: {ram_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa82b47-475a-465f-a7c8-e5bc50e60552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Disk Size: 235.98 GB\n"
     ]
    }
   ],
   "source": [
    "#3. Check Disk Info\n",
    "# Disk info\n",
    "disk = psutil.disk_usage('/')\n",
    "disk_total = disk.total / (1024 ** 3)\n",
    "print(f\"Total Disk Size: {disk_total:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42621943-e9cc-47b2-963a-eab2ac58560e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Windows\n",
      "Node Name: DESKTOP-DP8N41L\n",
      "Release: 10\n",
      "Version: 10.0.19045\n",
      "Machine: AMD64\n",
      "Processor: Intel64 Family 6 Model 142 Stepping 9, GenuineIntel\n"
     ]
    }
   ],
   "source": [
    "#4. Check System Info\n",
    "import platform\n",
    "\n",
    "print(\"System:\", platform.system())\n",
    "print(\"Node Name:\", platform.node())\n",
    "print(\"Release:\", platform.release())\n",
    "print(\"Version:\", platform.version())\n",
    "print(\"Machine:\", platform.machine())\n",
    "print(\"Processor:\", platform.processor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e447c3-9b62-4f1a-b585-543522231b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ System Information\n",
      "----------------------------\n",
      "System: Windows\n",
      "Release: 10\n",
      "Version: 10.0.19045\n",
      "Machine: AMD64\n",
      "Processor: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz\n",
      "Physical Cores: 4\n",
      "Total RAM: 15.87 GB\n",
      "Total Disk Size: 235.98 GB\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import multiprocessing\n",
    "import psutil\n",
    "from cpuinfo import get_cpu_info\n",
    "\n",
    "print(\"🖥️ System Information\")\n",
    "print(\"----------------------------\")\n",
    "print(\"System:\", platform.system())\n",
    "print(\"Release:\", platform.release())\n",
    "print(\"Version:\", platform.version())\n",
    "print(\"Machine:\", platform.machine())\n",
    "print(\"Processor:\", get_cpu_info()['brand_raw'])\n",
    "print(\"Physical Cores:\", multiprocessing.cpu_count())\n",
    "\n",
    "# RAM\n",
    "ram_gb = psutil.virtual_memory().total / (1024 ** 3)\n",
    "print(f\"Total RAM: {ram_gb:.2f} GB\")\n",
    "\n",
    "# Disk\n",
    "disk_total = psutil.disk_usage('/').total / (1024 ** 3)\n",
    "print(f\"Total Disk Size: {disk_total:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43007eb-337e-4b73-8892-c9bbfb27b616",
   "metadata": {},
   "source": [
    "### LLMs are based on deep learning techniques, utilizing architectures like transformers to process large volumes of text data. They are built through a series of essential steps: data collection, preprocessing, model architecture, training, fine-tuning, and deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b648b-3250-4ea2-beaa-cc709bb0c892",
   "metadata": {},
   "source": [
    "### What is an LLM?\n",
    "### LLM stands for Large Language Model. It is a type of advanced artificial intelligence model trained on large amounts of text data to understand and generate human-like text. These models are built using deep learning techniques and can perform a variety of natural language processing (NLP) tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5001b-4064-43dd-b53a-1a247f86af8d",
   "metadata": {},
   "source": [
    "## Components of an LLM\n",
    "\n",
    "### 1. Embedding Layers\n",
    "#### Converts words, phrases, or tokens into numerical vectors.\n",
    "#### These vectors capture the semantic meaning of the text, helping the model understand relationships between words.\n",
    "\n",
    "### 2. Attention Mechanism\n",
    "#### Helps the model focus on the most relevant parts of the input text.\n",
    "#### Example: If the task is translation, the model “attends” to the words in the input sentence that are most relevant to the word being generated.\n",
    "\n",
    "### 3. Transformer Blocks\n",
    "#### The core building blocks of an LLM.\n",
    "#### Consist of two main components:\n",
    "#### Self-Attention Layers: Process relationships between words in the input text.\n",
    "#### Feedforward Neural Networks: Perform additional computations to refine the understanding of the text.\n",
    "#### Multiple transformer blocks are stacked to improve the model’s performance on complex tasks.\n",
    "\n",
    "### 4. Positional Encoding\n",
    "#### Since transformers don’t process sequences in order, positional encoding helps the model understand the order of words in a sentence.\n",
    "\n",
    "### 5. Output Layers\n",
    "#### Generates predictions based on the processed input.\n",
    "#### For tasks like text generation, the output is a sequence of words or tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d8867-f57e-4ae3-a86f-b35042fdabf7",
   "metadata": {},
   "source": [
    "### Tasks LLMs Can Perform\n",
    "#### Text Generation\n",
    "#### Summarization\n",
    "#### Translation\n",
    "#### Question Answering\n",
    "#### Sentiment Analysis\n",
    "#### Text Completion\n",
    "#### Conversational AI\n",
    "#### Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b42dad-bfe7-45ac-9844-dd732a3dfd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps of Creating an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88bdf77-0a63-4160-b7ab-467b206602b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Wikipedia\n",
      "\n",
      "The Free Encyclopedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "English\n",
      "7,009,000+ articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "æ¥æ¬èª\n",
      "1,462,000+ è¨äº\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ð ÑÑÑÐºÐ¸Ð¹\n",
      "2Â 050Â 000+ ÑÑÐ°ÑÐµÐ¹\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Deutsch\n",
      "3.024.000+ Artikel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EspaÃ±ol\n",
      "2.041.000+ artÃ­culos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FranÃ§ais\n",
      "2â¯690â¯000+ articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ä¸­æ\n",
      "1,482,000+ æ¡ç® / æ¢ç®\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Italiano\n",
      "1.922.000+ voci\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PortuguÃªs\n",
      "1.148.000+ artigos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ÙØ§Ø±Ø³Û\n",
      "Û±Ù¬Û°Û´Û³Ù¬Û°Û°Û°+ Ù",
      "ÙØ§ÙÙ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Afrikaans\n",
      "Ø§ÙØ¹Ø±Ø¨ÙØ©\n",
      "Asturi\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Specify the URL\n",
    "url = \"https://wikipedia.com\"\n",
    "\n",
    "# Step 2: Send a GET request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 3: Parse the website content\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Step 4: Extract all text from the page\n",
    "text_data = soup.get_text()\n",
    "\n",
    "# Step 5: Print the first 500 characters of the text\n",
    "print(text_data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e68a6-0014-4302-bb04-41abbc09ce85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
